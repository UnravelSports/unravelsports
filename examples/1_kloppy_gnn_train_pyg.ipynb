{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸŒ€ unravel kloppy into graph neural network using the _new_ Polars back-end!\n",
    "\n",
    "### â€¼ï¸ NEW PYTORCH VERSION\n",
    "\n",
    "First run `pip install unravelsports` if you haven't already!\n",
    "\n",
    "\n",
    "-----\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install unravelsports torch torch-geometric pytorch-lightning --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this in-depth walkthrough we'll discuss everything the `unravelsports` package has to offer for converting a [Kloppy](https://github.com/PySport/kloppy) dataset of soccer tracking data into graphs for training binary classification graph neural networks using PyTorch Geometric and PyTorch Lightning, with a newly added (version==0.3.0+) [Polars](https://pola.rs/) back-end.\n",
    "\n",
    "This walkthrough will touch on a lot of the concepts from [A Graph Neural Network Deep-dive into Successful Counterattacks {A. Sahasrabudhe & J. Bekkers}](https://github.com/USSoccerFederation/ussf_ssac_23_soccer_gnn). It is strongly advised to first read the [research paper (pdf)](https://ussf-ssac-23-soccer-gnn.s3.us-east-2.amazonaws.com/public/Sahasrabudhe_Bekkers_SSAC23.pdf). Some concepts are also explained in the [Graphs FAQ](graphs_faq.md).\n",
    "\n",
    "Step by step we'll show how this package can be used to load soccer positional (tracking) data with `kloppy`, how to convert this data into a `KloppyPolarsDataset`, convert it into \"graphs\", train a Graph Neural Network with PyTorch Geometric, evaluate its performance, save and load the model and finally apply the model to unseen data to make predictions.\n",
    "\n",
    "The powerful Kloppy package allows us to load and standardize data from many providers: Metrica, Sportec, Tracab, SecondSpectrum, StatsPerform and SkillCorner. In this guide we'll use some matches from the [Public Sportec (DFL) Dataset (Bassek et al. 2025)](https://www.nature.com/articles/s41597-025-04505-y).\n",
    "\n",
    "<br>\n",
    "<i>Before we get started it is important to note that the <b>unravelsports</b> library does not have built in functionality to create binary labels, these will need to be supplied by the reader. In this example we use dummy labels instead. \n",
    "</i>\n",
    "<br>\n",
    "\n",
    "##### **Contents**\n",
    "\n",
    "- [**1. Imports**](#1-imports).\n",
    "- [**2. Public Sportec (DFL) Data**](#2-public-sportec-data).\n",
    "- [**3. â­ _KloppyPolarsDataset_ and _SoccerGraphConverter_**](#3-kloppypolarsdataset-and-soccergraphconverter).\n",
    "- [**4. Load Kloppy Data, Convert & Store**](#4-load-kloppy-data-convert-and-store).\n",
    "- [**5. Creating a Custom Graph Dataset**](#5-creating-a-custom-graph-dataset).\n",
    "- [**6. Prepare for Training**](#6-prepare-for-training).\n",
    "    - [6.1 Split Dataset](#61-split-dataset)\n",
    "    - [6.2 Model Configurations](#62-model-configurations)\n",
    "    - [6.3 Build GNN Model](#63-build-gnn-model)\n",
    "    - [6.4 Create DataLoaders](#64-create-dataloaders)\n",
    "- [**7. GNN Training + Prediction**](#7-training-and-prediction).\n",
    "    - [7.1 Initialize Trainer](#71-initialize-trainer)\n",
    "    - [7.2 Train Model](#72-train-model)\n",
    "    - [7.3 Save & Load Model](#73-save--load-model)\n",
    "    - [7.4 Evaluate Model](#74-evaluate-model)\n",
    "    - [7.5 Predict on New Data](#75-predict-on-new-data)\n",
    "\n",
    "â„¹ï¸ [**Graphs FAQ**](graphs_faq.md)\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Imports\n",
    "\n",
    "We import `SoccerGraphConverter` to help us convert from Kloppy positional tracking frames to graphs.\n",
    "\n",
    "With the power of **Kloppy** we can also load data from many providers by importing `metrica`, `sportec`, `tracab`, `secondspectrum`, `signality`, `pff`, `hawkeye` or `statsperform` from `kloppy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unravel.soccer import SoccerGraphConverter, KloppyPolarsDataset\n",
    "\n",
    "from kloppy import sportec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Public Sportec Data\n",
    "\n",
    "The `SoccerGraphConverter` class allows processing data from every tracking data provider supported by [PySports Kloppy](https://github.com/PySport/kloppy), namely:\n",
    "- Sportec\n",
    "- Tracab\n",
    "- SecondSpectrum\n",
    "- SkillCorner\n",
    "- StatsPerform\n",
    "- Metrica\n",
    "- PFF (beta)\n",
    "- HawkEye (alpha)\n",
    "- Signality (alpha)\n",
    "\n",
    "You can choose any of the following games from the open Sportec dataset:\n",
    "\n",
    "```python\n",
    "matches = {\n",
    "    'J03WMX': \"1. FC KÃ¶ln vs. FC Bayern MÃ¼nchen\",\n",
    "    'J03WN1': \"VfL Bochum 1848 vs. Bayer 04 Leverkusen\",\n",
    "    'J03WPY': \"Fortuna DÃ¼sseldorf vs. 1. FC NÃ¼rnberg\",\n",
    "    'J03WOH': \"Fortuna DÃ¼sseldorf vs. SSV Jahn Regensburg\",\n",
    "    'J03WQQ': \"Fortuna DÃ¼sseldorf vs. FC St. Pauli\",\n",
    "    'J03WOY': \"Fortuna DÃ¼sseldorf vs. F.C. Hansa Rostock\",\n",
    "    'J03WR9': \"Fortuna DÃ¼sseldorf vs. 1. FC Kaiserslautern\"\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. â­ _KloppyPolarsDataset_ and _SoccerGraphConverter_\n",
    "\n",
    "â„¹ï¸ For more information on:\n",
    "- What a Graph is, check out [Graph FAQ Section A](graphs_faq.ipynb)\n",
    "- What parameters we can pass to the `SoccerGraphConverter`, check out [Graph FAQ Section B](graphs_faq.ipynb)\n",
    "- What features each Graph has, check out [Graph FAQ Section C](graphs_faq.ipynb)\n",
    "\n",
    "------\n",
    "\n",
    "To get started we need to load our tracking data using Kloppy, and subsequently pass this to the `KloppyPolarsDataset`. \n",
    "\n",
    "This `KloppyPolarsDataset` also takes the following optional parameters:\n",
    "- ball_carrier_threshold: float = 25.0\n",
    "- max_player_speed: float = 12.0\n",
    "- max_ball_speed: float = 28.0\n",
    "- max_player_acceleration: float = 6.0\n",
    "- max_ball_acceleration: float = 13.5\n",
    "- orient_ball_owning: bool = True\n",
    "\n",
    "ğŸ—’ï¸ KloppyPolarsDataset sets the orientation to `Orientation.BALL_OWNING_TEAM` (ball owning team plays left to right) when `orient_ball_owning=True`. This is preferred behaviour in this use-case.\n",
    "\n",
    "If our dataset does not have the ball owning team we infer the ball owning team automatically using the `ball_carrier_threshold` and subsequently change the orientation automatically to be left to right for the ball owning team too. Additionally, we automatically identify the ball carrying player as the player on the ball owning team closest to the ball.\n",
    "\n",
    "ğŸ—’ï¸ In `SoccerGraphConverter` [deprecated] if the ball owning team was not available we set the orientation to STATIC_HOME_AWAY meaning attacking could happen in two directions. \n",
    "\n",
    "<div style=\"border: 2px solid #ddd; border-radius: 5px; padding: 10px; background-color: ##282C34;\">\n",
    "<pre>\n",
    "kloppy_dataset = sportec.load_open_tracking_data(\n",
    "    match_id=match_id,\n",
    "    coordinates=\"secondspectrum\",\n",
    "    alive_only=True,\n",
    "    limit=500,  \n",
    ")\n",
    "kloppy_polars_dataset = KloppyPolarsDataset(\n",
    "    kloppy_dataset=kloppy_dataset,\n",
    "    ball_carrier_threshold=25.0\n",
    ")\n",
    "</pre>\n",
    "</div>\n",
    "\n",
    "#### Graph Identifier(s):\n",
    "After loading the `kloppy_polars_dataset` we now add graph identifiers. We can do this by passing a list of column names on which we want to split our data.\n",
    "\n",
    "ğŸ—’ï¸ When training a model on tracking data it's highly recommended to split data into test/train(/validation) sets by match or period such that all data end up in the same test, train or validation set. This should be done to avoid leaking information between test, train and validation sets. Correctly splitting the final dataset in train, test and validiation sets using these Graph Identifiers is incorporated into `GraphDataset` (see [Section 6.1](#61-split-dataset) for more information).\n",
    "\n",
    "<div style=\"border: 2px solid #ddd; border-radius: 5px; padding: 10px; background-color: ##282C34;\">\n",
    "<pre>\n",
    "kloppy_polars_dataset.add_graph_ids(by=[\"period_id\", \"match_id\"])\n",
    "</pre>\n",
    "</div>\n",
    "\n",
    "#### Labels:\n",
    "For training any model we need labels. If your labels are stored in some other dataset format, for example a CSV file, you can join those labels on your `kloppy_polars_dataset.data` (which is a polars DataFrame).\n",
    "\n",
    "ğŸ—’ï¸ For this tutorial we'll use the `dummy_labels()` method that assigns a random binary label to each frame. In a real scenario, you would join your actual labels here.\n",
    "\n",
    "<div style=\"border: 2px solid #ddd; border-radius: 5px; padding: 10px; background-color: ##282C34;\">\n",
    "<pre>\n",
    "kloppy_polars_dataset.add_dummy_labels()\n",
    "</pre>\n",
    "</div>\n",
    "\n",
    "#### Initialize SoccerGraphConverter:\n",
    "After loading the `kloppy_polars_dataset`, adding graph identifiers, and adding labels, we can initialize the `SoccerGraphConverter`.\n",
    "\n",
    "The `SoccerGraphConverter` takes many optional parameters to customize how graphs are constructed. For a complete overview, see the [Graph FAQ Section B](graphs_faq.ipynb).\n",
    "\n",
    "Key parameters include:\n",
    "- `self_loop_ball`: Whether to add self-loops to the ball node\n",
    "- `adjacency_matrix_connect_type`: How to connect nodes (\"ball\", \"delaunay\", \"radius\", etc.)\n",
    "- `adjacency_matrix_type`: Type of adjacency matrix (\"split_by_team\", \"dense\", \"delaunay\")\n",
    "- `label_type`: Type of label (\"binary\", \"multilabel\")\n",
    "- `defending_team_node_value`: Value to assign to defending team nodes\n",
    "- `non_potential_receiver_node_value`: Value to assign to non-potential receiver nodes\n",
    "- `random_seed`: Random seed for reproducibility\n",
    "- `pad`: Whether to pad graphs to a fixed size\n",
    "- `verbose`: Whether to print progress information\n",
    "\n",
    "<div style=\"border: 2px solid #ddd; border-radius: 5px; padding: 10px; background-color: ##282C34;\">\n",
    "<pre>\n",
    "converter = SoccerGraphConverter(\n",
    "    dataset=kloppy_polars_dataset,\n",
    "    self_loop_ball=True,\n",
    "    adjacency_matrix_connect_type=\"ball\",\n",
    "    adjacency_matrix_type=\"split_by_team\",\n",
    "    label_type=\"binary\",\n",
    "    defending_team_node_value=0.1,\n",
    "    non_potential_receiver_node_value=0.1,\n",
    "    random_seed=42,\n",
    "    pad=False,\n",
    "    verbose=False,\n",
    ")\n",
    "</pre>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Load Kloppy Data, Convert and Store\n",
    "\n",
    "Now we'll put it all together and process multiple matches from the Sportec dataset.\n",
    "\n",
    "We'll:\n",
    "1. Loop through multiple match IDs\n",
    "2. Load each match with Kloppy\n",
    "3. Create a KloppyPolarsDataset\n",
    "4. Add graph identifiers and labels\n",
    "5. Convert to PyTorch Geometric graphs\n",
    "6. Store all graphs for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing match: J03WMX\n",
      "  Generated 500 graphs from match J03WMX\n",
      "Processing match: J03WN1\n",
      "  Generated 500 graphs from match J03WN1\n",
      "Processing match: J03WPY\n",
      "  Generated 500 graphs from match J03WPY\n",
      "\n",
      "Total graphs generated: 1500\n"
     ]
    }
   ],
   "source": [
    "from unravel.utils import GraphDataset\n",
    "\n",
    "# Select matches to process\n",
    "match_ids = [\"J03WMX\", \"J03WN1\", \"J03WPY\"]  # Add more as needed\n",
    "\n",
    "all_graphs = []\n",
    "\n",
    "for match_id in match_ids:\n",
    "    print(f\"Processing match: {match_id}\")\n",
    "\n",
    "    # Load Kloppy dataset\n",
    "    kloppy_dataset = sportec.load_open_tracking_data(\n",
    "        match_id=match_id,\n",
    "        only_alive=True,\n",
    "        limit=500,  # Remove this limit for full match processing\n",
    "    )\n",
    "\n",
    "    # Create KloppyPolarsDataset\n",
    "    kloppy_polars_dataset = KloppyPolarsDataset(\n",
    "        kloppy_dataset=kloppy_dataset,\n",
    "        ball_carrier_threshold=25.0,\n",
    "    )\n",
    "\n",
    "    # Add graph identifiers\n",
    "    kloppy_polars_dataset.add_graph_ids()\n",
    "\n",
    "    # Add labels (in practice, you would join your actual labels here)\n",
    "    kloppy_polars_dataset.add_dummy_labels()\n",
    "\n",
    "    # Initialize converter with desired settings\n",
    "    converter = SoccerGraphConverter(\n",
    "        dataset=kloppy_polars_dataset,\n",
    "        self_loop_ball=True,\n",
    "        adjacency_matrix_connect_type=\"ball\",\n",
    "        adjacency_matrix_type=\"split_by_team\",\n",
    "        label_type=\"binary\",\n",
    "        defending_team_node_value=0.1,\n",
    "        non_potential_receiver_node_value=0.1,\n",
    "        random_seed=42,\n",
    "        pad=False,\n",
    "        verbose=False,\n",
    "    )\n",
    "\n",
    "    # Convert to PyTorch Geometric graphs\n",
    "    graphs = converter.to_pytorch_graphs()\n",
    "    all_graphs.extend(graphs)\n",
    "\n",
    "    print(f\"  Generated {len(graphs)} graphs from match {match_id}\")\n",
    "\n",
    "print(f\"\\nTotal graphs generated: {len(all_graphs)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Creating a Custom Graph Dataset\n",
    "\n",
    "Now that we have all our graphs, we'll create a `GraphDataset` that makes it easy to work with PyTorch Geometric.\n",
    "\n",
    "The `GraphDataset` class provides:\n",
    "- Easy data splitting (train/test/validation)\n",
    "- Compatibility with PyTorch Geometric DataLoaders\n",
    "- Automatic batching capabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset contains 1500 graphs\n",
      "First graph: Data(x=[23, 15], edge_index=[2, 287], edge_attr=[287, 6], y=[1], id='DFL-MAT-J03WMX-1', frame_id=10534, ball_owning_team_id='DFL-CLU-000008')\n"
     ]
    }
   ],
   "source": [
    "# Create the dataset\n",
    "dataset = GraphDataset(graphs=all_graphs, format=\"pyg\")\n",
    "\n",
    "print(f\"Dataset contains {len(dataset)} graphs\")\n",
    "print(f\"First graph: {dataset[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Prepare for Training\n",
    "\n",
    "Now we'll prepare everything needed to train our Graph Neural Network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.1 Split Dataset\n",
    "\n",
    "We split the dataset into train, test, and validation sets. The `split_test_train_validation` method respects the graph identifiers we set earlier, ensuring that all frames from the same period/match stay together.\n",
    "\n",
    "ğŸ—’ï¸ This prevents data leakage between sets, which is crucial for accurate model evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: 900 graphs\n",
      "Test set: 300 graphs\n",
      "Validation set: 300 graphs\n"
     ]
    }
   ],
   "source": [
    "# Split the dataset: 60% train, 20% test, 20% validation\n",
    "train, test, val = dataset.split_test_train_validation(\n",
    "    split_train=3,\n",
    "    split_test=1,\n",
    "    split_validation=1,\n",
    "    random_seed=42,\n",
    ")\n",
    "\n",
    "print(f\"Training set: {len(train)} graphs\")\n",
    "print(f\"Test set: {len(test)} graphs\")\n",
    "print(f\"Validation set: {len(val)} graphs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.2 Model Configurations\n",
    "\n",
    "We'll set up the model hyperparameters. These settings are based on the research paper mentioned earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model hyperparameters\n",
    "n_layers = 3\n",
    "channels = 128\n",
    "drop_out = 0.5\n",
    "n_out = 1  # Binary classification\n",
    "\n",
    "# Training hyperparameters\n",
    "batch_size = 32\n",
    "max_epochs = 50\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.3 Build GNN Model\n",
    "\n",
    "We initialize the PyTorch Lightning model, which wraps our PyTorch Geometric GNN with training logic, metrics, and optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unravel.classifiers import PyGLightningCrystalGraphClassifier\n",
    "import pytorch_lightning as pyl\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "# Initialize the Lightning model\n",
    "model = PyGLightningCrystalGraphClassifier(\n",
    "    n_layers=n_layers,\n",
    "    channels=channels,\n",
    "    drop_out=drop_out,\n",
    "    n_out=n_out,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.4 Create DataLoaders\n",
    "\n",
    "PyTorch Geometric DataLoaders handle batching and shuffling of our graph data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader: 29 batches\n",
      "Validation loader: 10 batches\n",
      "Test loader: 10 batches\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(train, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "print(f\"Train loader: {len(train_loader)} batches\")\n",
    "print(f\"Validation loader: {len(val_loader)} batches\")\n",
    "print(f\"Test loader: {len(test_loader)} batches\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Training and Prediction\n",
    "\n",
    "Now we're ready to train our model!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.1 Initialize Trainer\n",
    "\n",
    "PyTorch Lightning's Trainer handles the training loop, logging, and callbacks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n"
     ]
    }
   ],
   "source": [
    "# Set up callbacks\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    dirpath=\"models/\",\n",
    "    filename=\"best-model-{epoch:02d}-{val_auc:.2f}\",\n",
    "    save_top_k=1,\n",
    "    monitor=\"val_auc\",\n",
    "    mode=\"max\",\n",
    ")\n",
    "\n",
    "early_stop_callback = EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    patience=5,\n",
    "    mode=\"min\",\n",
    ")\n",
    "\n",
    "# Initialize trainer\n",
    "trainer = pyl.Trainer(\n",
    "    max_epochs=max_epochs,\n",
    "    accelerator=\"auto\",  # Automatically uses GPU if available\n",
    "    callbacks=[checkpoint_callback, early_stop_callback],\n",
    "    log_every_n_steps=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.2 Train Model\n",
    "\n",
    "Now we train the model on our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jbekkers/PycharmProjects/unravelsports/.venv311/lib/python3.11/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:751: Checkpoint directory /Users/jbekkers/PycharmProjects/unravelsports/models exists and is not empty.\n",
      "W1127 14:30:43.342000 97361 torch/distributed/elastic/multiprocessing/redirects.py:29] NOTE: Redirects are currently not supported in Windows or MacOs.\n",
      "/Users/jbekkers/PycharmProjects/unravelsports/.venv311/lib/python3.11/site-packages/pytorch_lightning/utilities/model_summary/model_summary.py:493: The total number of parameters detected may be inaccurate because the model contains an instance of `UninitializedParameter`. To get an accurate number, set `self.example_input_array` in your LightningModule.\n",
      "\n",
      "  | Name      | Type                      | Params | Mode \n",
      "----------------------------------------------------------------\n",
      "0 | model     | PyGCrystalGraphClassifier | 328 K  | train\n",
      "1 | criterion | BCELoss                   | 0      | train\n",
      "2 | train_auc | BinaryAUROC               | 0      | train\n",
      "3 | train_acc | BinaryAccuracy            | 0      | train\n",
      "4 | val_auc   | BinaryAUROC               | 0      | train\n",
      "5 | val_acc   | BinaryAccuracy            | 0      | train\n",
      "6 | test_auc  | BinaryAUROC               | 0      | train\n",
      "7 | test_acc  | BinaryAccuracy            | 0      | train\n",
      "----------------------------------------------------------------\n",
      "328 K     Trainable params\n",
      "0         Non-trainable params\n",
      "328 K     Total params\n",
      "1.315     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ab31e4e499046189cabe3b8bdb4cc0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jbekkers/PycharmProjects/unravelsports/.venv311/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:433: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "/Users/jbekkers/PycharmProjects/unravelsports/.venv311/lib/python3.11/site-packages/pytorch_lightning/utilities/data.py:79: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 736. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "/Users/jbekkers/PycharmProjects/unravelsports/.venv311/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:433: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f2f2564759342dd8309bc0752efa274",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jbekkers/PycharmProjects/unravelsports/.venv311/lib/python3.11/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/Users/jbekkers/PycharmProjects/unravelsports/.venv311/lib/python3.11/site-packages/pytorch_lightning/utilities/data.py:79: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 92. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "818d036c19d341aea1354bdc1ecddc9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jbekkers/PycharmProjects/unravelsports/.venv311/lib/python3.11/site-packages/pytorch_lightning/utilities/data.py:79: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 276. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b60f26e486f40deaa8e3e52f93bda3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51546a26b6744249b16faa35579c124d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9db1ec26753a403b9b1cc753866724b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jbekkers/PycharmProjects/unravelsports/.venv311/lib/python3.11/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "082a778bbc9c4b28826b8eaab98f6542",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2da5be91abf94b8e8987fa715a1912a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48072fe9706246e3b1b111cff9974eee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14b9b6ad015b4c8f8cb9623dd1edddb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52fa2694a5204a53849093186af2ae67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b31a29ff61b4baea89d8b73f598b8dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c65bac5bcd3a4840bb3aeb0b01b1c03c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "312d6e4c9c6044bbb0f77d4752b65787",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc08e2cb96c34be1aaa40795d79b812b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9217855813e846eba342dfa12e0f5d5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25d90c8e7bd24d46b1fea349a9059f4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train the model\n",
    "trainer.fit(model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.3 Save & Load Model\n",
    "\n",
    "PyTorch Lightning makes it easy to save and load models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The best model is already saved by the checkpoint callback\n",
    "# But we can also manually save\n",
    "model_path = \"models/my-graph-classifier.ckpt\"\n",
    "trainer.save_checkpoint(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "loaded_model = PyGLightningCrystalGraphClassifier.load_from_checkpoint(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.4 Evaluate Model\n",
    "\n",
    "Let's evaluate the model on our test set.\n",
    "\n",
    "ğŸ—’ï¸ Our performance might be poor because we're using random labels, limited epochs, and a small dataset.\n",
    "\n",
    "ğŸ“– For more information on evaluation in sports analytics see: [Methodology and evaluation in sports analytics: challenges, approaches, and lessons learned {J. Davis et. al. (2024)}](https://link.springer.com/article/10.1007/s10994-024-06585-0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jbekkers/PycharmProjects/unravelsports/.venv311/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:433: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7e2e01e044b4442af7142434996eed8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ<span style=\"font-weight: bold\">        Test metric        </span>â”ƒ<span style=\"font-weight: bold\">       DataLoader 0        </span>â”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚<span style=\"color: #008080; text-decoration-color: #008080\">         test_acc          </span>â”‚<span style=\"color: #800080; text-decoration-color: #800080\">    0.46666666865348816    </span>â”‚\n",
       "â”‚<span style=\"color: #008080; text-decoration-color: #008080\">         test_auc          </span>â”‚<span style=\"color: #800080; text-decoration-color: #800080\">    0.5134821534156799     </span>â”‚\n",
       "â”‚<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>â”‚<span style=\"color: #800080; text-decoration-color: #800080\">    0.6954680681228638     </span>â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
       "</pre>\n"
      ],
      "text/plain": [
       "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚\u001b[36m \u001b[0m\u001b[36m        test_acc         \u001b[0m\u001b[36m \u001b[0mâ”‚\u001b[35m \u001b[0m\u001b[35m   0.46666666865348816   \u001b[0m\u001b[35m \u001b[0mâ”‚\n",
       "â”‚\u001b[36m \u001b[0m\u001b[36m        test_auc         \u001b[0m\u001b[36m \u001b[0mâ”‚\u001b[35m \u001b[0m\u001b[35m   0.5134821534156799    \u001b[0m\u001b[35m \u001b[0mâ”‚\n",
       "â”‚\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0mâ”‚\u001b[35m \u001b[0m\u001b[35m   0.6954680681228638    \u001b[0m\u001b[35m \u001b[0mâ”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'test_loss': 0.6954680681228638, 'test_auc': 0.5134821534156799, 'test_acc': 0.46666666865348816}]\n"
     ]
    }
   ],
   "source": [
    "# Test the model\n",
    "test_results = trainer.test(model, test_loader)\n",
    "\n",
    "print(test_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.5 Predict on New Data\n",
    "\n",
    "1. Load new, unseen data from the Sportec dataset.\n",
    "2. Convert this data, making sure we use the exact same settings as in step 4.\n",
    "3. If we set `prediction=True` we do not have to supply labels to the `SoccerGraphConverter`.\n",
    "4. We do still need to add graph_ids. It is advised to do this by \"frame_id\" for the prediction, such that we can more easily merge the predictions back to the correct frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a new match for prediction (one we haven't used for training)\n",
    "kloppy_dataset = sportec.load_open_tracking_data(\n",
    "    match_id=\"J03WR9\",  # A game we have not yet used in section 4\n",
    "    only_alive=True,\n",
    "    limit=500,\n",
    ")\n",
    "\n",
    "pred_kloppy_polars = KloppyPolarsDataset(\n",
    "    kloppy_dataset=kloppy_dataset,\n",
    "    ball_carrier_threshold=25.0,\n",
    ")\n",
    "pred_kloppy_polars.add_graph_ids(by=[\"frame_id\"])\n",
    "\n",
    "# Create converter with same settings as training, but with prediction=True\n",
    "preds_converter = SoccerGraphConverter(\n",
    "    dataset=pred_kloppy_polars,\n",
    "    # Settings (MUST match training settings)\n",
    "    prediction=True,\n",
    "    self_loop_ball=True,\n",
    "    adjacency_matrix_connect_type=\"ball\",\n",
    "    adjacency_matrix_type=\"split_by_team\",\n",
    "    label_type=\"binary\",\n",
    "    defending_team_node_value=0.1,\n",
    "    non_potential_receiver_node_value=0.1,\n",
    "    random_seed=False,\n",
    "    pad=False,\n",
    "    verbose=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Make a prediction on all the frames of this dataset using `trainer.predict`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jbekkers/PycharmProjects/unravelsports/.venv311/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:433: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2dadd10027d448518c875e46f90ccd4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 500 predictions\n",
      "Prediction shape: (500,)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Compute the graphs and add them to the GraphDataset\n",
    "pred_graphs = preds_converter.to_pytorch_graphs()\n",
    "pred_dataset = GraphDataset(graphs=pred_graphs, format=\"pyg\")\n",
    "\n",
    "# Create data loader for predictions\n",
    "pred_loader = DataLoader(pred_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Get predictions\n",
    "predictions = trainer.predict(model, pred_loader)\n",
    "\n",
    "# Concatenate predictions from all batches\n",
    "all_predictions = torch.cat(predictions).cpu().numpy()\n",
    "\n",
    "print(f\"Generated {len(all_predictions)} predictions\")\n",
    "print(f\"Prediction shape: {all_predictions.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Create a predictions Polars DataFrame\n",
    "\n",
    "We merge the `preds_df` to the `KloppyPolarsDataset` named `pred_kloppy_polars` that we just applied the predictions to.\n",
    "\n",
    "ğŸ—’ï¸ We use `\"frame_id\"` here because the prediction dataset \"x.id\" is the Graph Ids we added above. We did this on the `\"frame_id\"` too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample predictions:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (10, 4)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>frame_id</th><th>period_id</th><th>timestamp</th><th>y_hat</th></tr><tr><td>i64</td><td>i64</td><td>duration[Î¼s]</td><td>f32</td></tr></thead><tbody><tr><td>10012</td><td>1</td><td>480ms</td><td>0.485382</td></tr><tr><td>10012</td><td>1</td><td>480ms</td><td>0.485382</td></tr><tr><td>10012</td><td>1</td><td>480ms</td><td>0.485382</td></tr><tr><td>10012</td><td>1</td><td>480ms</td><td>0.485382</td></tr><tr><td>10013</td><td>1</td><td>520ms</td><td>0.485365</td></tr><tr><td>10013</td><td>1</td><td>520ms</td><td>0.485365</td></tr><tr><td>10013</td><td>1</td><td>520ms</td><td>0.485365</td></tr><tr><td>10013</td><td>1</td><td>520ms</td><td>0.485365</td></tr><tr><td>10013</td><td>1</td><td>520ms</td><td>0.485365</td></tr><tr><td>10013</td><td>1</td><td>520ms</td><td>0.485365</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (10, 4)\n",
       "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
       "â”‚ frame_id â”† period_id â”† timestamp    â”† y_hat    â”‚\n",
       "â”‚ ---      â”† ---       â”† ---          â”† ---      â”‚\n",
       "â”‚ i64      â”† i64       â”† duration[Î¼s] â”† f32      â”‚\n",
       "â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•¡\n",
       "â”‚ 10012    â”† 1         â”† 480ms        â”† 0.485382 â”‚\n",
       "â”‚ 10012    â”† 1         â”† 480ms        â”† 0.485382 â”‚\n",
       "â”‚ 10012    â”† 1         â”† 480ms        â”† 0.485382 â”‚\n",
       "â”‚ 10012    â”† 1         â”† 480ms        â”† 0.485382 â”‚\n",
       "â”‚ 10013    â”† 1         â”† 520ms        â”† 0.485365 â”‚\n",
       "â”‚ 10013    â”† 1         â”† 520ms        â”† 0.485365 â”‚\n",
       "â”‚ 10013    â”† 1         â”† 520ms        â”† 0.485365 â”‚\n",
       "â”‚ 10013    â”† 1         â”† 520ms        â”† 0.485365 â”‚\n",
       "â”‚ 10013    â”† 1         â”† 520ms        â”† 0.485365 â”‚\n",
       "â”‚ 10013    â”† 1         â”† 520ms        â”† 0.485365 â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import polars as pl\n",
    "\n",
    "# Create predictions DataFrame\n",
    "preds_df = pl.DataFrame(\n",
    "    {\"frame_id\": [int(x.id) for x in pred_dataset], \"y_hat\": all_predictions.flatten()}\n",
    ")\n",
    "preds_df = preds_df.sort(\"y_hat\")\n",
    "\n",
    "# Join predictions back to the original data\n",
    "pred_kloppy_polars.data = pred_kloppy_polars.data.join(\n",
    "    preds_df, on=\"frame_id\", how=\"left\"\n",
    ")\n",
    "\n",
    "# Display a sample of predictions\n",
    "print(\"\\nSample predictions:\")\n",
    "pred_kloppy_polars.data[295:305][[\"frame_id\", \"period_id\", \"timestamp\", \"y_hat\"]]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
