{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸŒ€ Quick Start Guide: It's all starting to unravel!\n",
    "\n",
    "### â€¼ï¸ NEW PYTORCH VERSION\n",
    "\n",
    "In this example we'll run through all the basic features the `unravelsports` package offers for converting a `kloppy` dataset of soccer tracking data into graphs for training binary classification graph neural networks using PyTorch Geometric and PyTorch Lightning.\n",
    "\n",
    "This guide will go through the following steps:\n",
    "\n",
    "- [**1. Process Data**](#1-processing-data). We'll show how to load a `kloppy` dataset and convert each individual frame into a single graph. All necessary steps (like setting the correct coordinate system, and left-right normalization) are done under the hood of the converter.\n",
    "- [**1.1 Split Data**](#11-split-data).\n",
    "- [**2. Initialize Model**](#2-initialize-model). We initialize the built-in binary classification model as presented in [A Graph Neural Network Deep-dive into Successful Counterattacks {A. Sahasrabudhe & J. Bekkers}](https://github.com/USSoccerFederation/ussf_ssac_23_soccer_gnn).\n",
    "- [**3. Train Model**](#3-train-model). Using the initialized model we train it on the training set created in step [1.1 Splitting Data](#11-split-data).\n",
    "- [**4. Evaluate Model Performance**](#4-evaluate-model-performance). We calculate model performance using the metrics defined in the model.\n",
    "- [**5. Predict**](#5-predict). Finally, we apply the trained model to unseen data.\n",
    "- [**6. Save & Load Model**](#6-save--load-model). Learn how to save and reload your trained models.\n",
    "\n",
    "<br>\n",
    "<i>Before we get started it is important to note that the <b>unravelsports</b> library does not have built in functionality to create binary labels, these will need to be supplied by the reader. In this example we use the <b>dummy_labels()</b> functionality that comes with the package. This function creates a single binary label for each frame by randomly assigning it a 0 or 1 value.\n",
    "\n",
    "When supplying your own labels they need to be in the form of a dictionary (more information on this can be found in the [in-depth Walkthrough](1_kloppy_gnn_train.ipynb)) </i>\n",
    "\n",
    "\n",
    "\n",
    "-----\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing is to run `pip install unravelsports` if you haven't already!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install unravelsports torch torch-geometric pytorch-lightning --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Process Data\n",
    "\n",
    "1. Load [Kloppy](https://github.com/PySport/kloppy) dataset. \n",
    "    See [in-depth Tutorial](1_kloppy_gnn_train.ipynb) on how to process multiple match files, and to see an overview of all possible settings.\n",
    "2. Convert to Graph format using `SoccerGraphConverter`\n",
    "3. Create dataset for easy processing with PyTorch Geometric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unravel.soccer import SoccerGraphConverter, KloppyPolarsDataset\n",
    "from unravel.utils import GraphDataset\n",
    "\n",
    "from kloppy import sportec\n",
    "\n",
    "# Load Kloppy dataset\n",
    "kloppy_dataset = sportec.load_open_tracking_data(only_alive=True, limit=500)\n",
    "kloppy_polars_dataset = KloppyPolarsDataset(\n",
    "    kloppy_dataset=kloppy_dataset,\n",
    ")\n",
    "kloppy_polars_dataset.add_dummy_labels()\n",
    "kloppy_polars_dataset.add_graph_ids(by=[\"frame_id\"])\n",
    "\n",
    "# Initialize the Graph Converter with dataset\n",
    "# Here we use the default settings\n",
    "converter = SoccerGraphConverter(dataset=kloppy_polars_dataset)\n",
    "\n",
    "# Compute the graphs and add them to the GraphDataset\n",
    "pyg_graphs = converter.to_pytorch_graphs()\n",
    "dataset = GraphDataset(graphs=pyg_graphs, format=\"pyg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 Split Data\n",
    "\n",
    "Split the dataset with the built in `split_test_train_validation` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test, val = dataset.split_test_train_validation(\n",
    "    split_train=4, split_test=1, split_validation=1, random_seed=43\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Initialize Model\n",
    "\n",
    "1. Initialize the `PyGLightningCrystalGraphClassifier` with PyTorch Lightning.\n",
    "2. Set up callbacks for model checkpointing and early stopping.\n",
    "3. Initialize the trainer.\n",
    "\n",
    "Note: The model settings are chosen to reflect the model used in [A Graph Neural Network Deep-dive into Successful Counterattacks {A. Sahasrabudhe & J. Bekkers}](https://github.com/USSoccerFederation/ussf_ssac_23_soccer_gnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n"
     ]
    }
   ],
   "source": [
    "from unravel.classifiers import PyGLightningCrystalGraphClassifier\n",
    "import pytorch_lightning as pyl\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "# Initialize the Lightning model\n",
    "lit_model = PyGLightningCrystalGraphClassifier(\n",
    "    n_layers=3, channels=128, drop_out=0.5, n_out=1\n",
    ")\n",
    "\n",
    "# Set up callbacks\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    dirpath=\"models/\",\n",
    "    filename=\"best-model-{epoch:02d}-{val_auc:.2f}\",\n",
    "    save_top_k=1,\n",
    "    monitor=\"val_auc\",\n",
    "    mode=\"max\",\n",
    ")\n",
    "\n",
    "early_stop_callback = EarlyStopping(monitor=\"val_loss\", patience=5, mode=\"min\")\n",
    "\n",
    "# Initialize trainer\n",
    "trainer = pyl.Trainer(\n",
    "    max_epochs=10,\n",
    "    accelerator=\"auto\",  # Automatically uses GPU if available\n",
    "    callbacks=[checkpoint_callback, early_stop_callback],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Train Model\n",
    "\n",
    "1. Create PyTorch Geometric `DataLoader` for training and validation sets.\n",
    "2. Train the model using PyTorch Lightning's `trainer.fit()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jbekkers/PycharmProjects/unravelsports/.venv311/lib/python3.11/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:751: Checkpoint directory /Users/jbekkers/PycharmProjects/unravelsports/models exists and is not empty.\n",
      "W1127 14:12:13.905000 99669 torch/distributed/elastic/multiprocessing/redirects.py:29] NOTE: Redirects are currently not supported in Windows or MacOs.\n",
      "/Users/jbekkers/PycharmProjects/unravelsports/.venv311/lib/python3.11/site-packages/pytorch_lightning/utilities/model_summary/model_summary.py:493: The total number of parameters detected may be inaccurate because the model contains an instance of `UninitializedParameter`. To get an accurate number, set `self.example_input_array` in your LightningModule.\n",
      "\n",
      "  | Name      | Type                      | Params | Mode \n",
      "----------------------------------------------------------------\n",
      "0 | model     | PyGCrystalGraphClassifier | 328 K  | train\n",
      "1 | criterion | BCELoss                   | 0      | train\n",
      "2 | train_auc | BinaryAUROC               | 0      | train\n",
      "3 | train_acc | BinaryAccuracy            | 0      | train\n",
      "4 | val_auc   | BinaryAUROC               | 0      | train\n",
      "5 | val_acc   | BinaryAccuracy            | 0      | train\n",
      "6 | test_auc  | BinaryAUROC               | 0      | train\n",
      "7 | test_acc  | BinaryAccuracy            | 0      | train\n",
      "----------------------------------------------------------------\n",
      "328 K     Trainable params\n",
      "0         Non-trainable params\n",
      "328 K     Total params\n",
      "1.315     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2da75b445f746f19930dbb206f1b7cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jbekkers/PycharmProjects/unravelsports/.venv311/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:433: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "/Users/jbekkers/PycharmProjects/unravelsports/.venv311/lib/python3.11/site-packages/pytorch_lightning/utilities/data.py:79: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 736. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "/Users/jbekkers/PycharmProjects/unravelsports/.venv311/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:433: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "/Users/jbekkers/PycharmProjects/unravelsports/.venv311/lib/python3.11/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (11) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9520815bdc1545a19f9674cec7a31b1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jbekkers/PycharmProjects/unravelsports/.venv311/lib/python3.11/site-packages/pytorch_lightning/utilities/data.py:79: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 299. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4367d331e1b34617b90c954ef312dff4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jbekkers/PycharmProjects/unravelsports/.venv311/lib/python3.11/site-packages/pytorch_lightning/utilities/data.py:79: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 460. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eadfced12ebd4275a069e9edf68aa111",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ea3bc19e30a4e50af5eead076e3b0df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ce36dd156634881993895e7d928ebe2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "317dee14a96043eba3d7cbba504d9b94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "013eb4bae2e444938beef7f9cc68af22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8dedf0db27b4f92bd7107b01c836a6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da009ece6b6f4859bcf52e0c7baa2fbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b06e041477854020b2f7e2cfb975b030",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aba06e03b5564d02a0b6d1acbb365a33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "# Create data loaders\n",
    "loader_tr = DataLoader(train, batch_size=batch_size, shuffle=True)\n",
    "loader_va = DataLoader(val, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Train the model\n",
    "trainer.fit(lit_model, loader_tr, loader_va)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Evaluate Model Performance\n",
    "\n",
    "1. Create a PyTorch Geometric `DataLoader` for the test set.\n",
    "2. Use `trainer.test()` to evaluate. This automatically uses the metrics defined in the Lightning module.\n",
    "\n",
    "Note: Our performance is really bad because we're using random labels, very few epochs and a small dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jbekkers/PycharmProjects/unravelsports/.venv311/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:433: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fa4887c5e624157adbc9ce57a68d463",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jbekkers/PycharmProjects/unravelsports/.venv311/lib/python3.11/site-packages/pytorch_lightning/utilities/data.py:79: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 437. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ<span style=\"font-weight: bold\">        Test metric        </span>â”ƒ<span style=\"font-weight: bold\">       DataLoader 0        </span>â”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚<span style=\"color: #008080; text-decoration-color: #008080\">         test_acc          </span>â”‚<span style=\"color: #800080; text-decoration-color: #800080\">    0.46987950801849365    </span>â”‚\n",
       "â”‚<span style=\"color: #008080; text-decoration-color: #008080\">         test_auc          </span>â”‚<span style=\"color: #800080; text-decoration-color: #800080\">    0.5180652141571045     </span>â”‚\n",
       "â”‚<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>â”‚<span style=\"color: #800080; text-decoration-color: #800080\">    0.7092337012290955     </span>â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
       "</pre>\n"
      ],
      "text/plain": [
       "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚\u001b[36m \u001b[0m\u001b[36m        test_acc         \u001b[0m\u001b[36m \u001b[0mâ”‚\u001b[35m \u001b[0m\u001b[35m   0.46987950801849365   \u001b[0m\u001b[35m \u001b[0mâ”‚\n",
       "â”‚\u001b[36m \u001b[0m\u001b[36m        test_auc         \u001b[0m\u001b[36m \u001b[0mâ”‚\u001b[35m \u001b[0m\u001b[35m   0.5180652141571045    \u001b[0m\u001b[35m \u001b[0mâ”‚\n",
       "â”‚\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0mâ”‚\u001b[35m \u001b[0m\u001b[35m   0.7092337012290955    \u001b[0m\u001b[35m \u001b[0mâ”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'test_loss': 0.7092337012290955, 'test_auc': 0.5180652141571045, 'test_acc': 0.46987950801849365}]\n"
     ]
    }
   ],
   "source": [
    "loader_te = DataLoader(test, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Test and get metrics\n",
    "test_results = trainer.test(lit_model, loader_te)\n",
    "print(test_results)\n",
    "# Output: [{'test_loss': 0.234, 'test_auc': 0.85, 'test_acc': 0.78}]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Predict\n",
    "\n",
    "1. Use unseen data to predict on. In this example we're using the test dataset.\n",
    "2. We have to re-create `loader_te` because the previous one was consumed.\n",
    "3. Predictions come as a list of tensors (one per batch), so we concatenate them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jbekkers/PycharmProjects/unravelsports/.venv311/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:433: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05e990753d5948c4835ea08e67809bb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions shape: (83,)\n",
      "First 10 predictions: [0.43283835 0.4399156  0.43866515 0.4338897  0.44259036 0.42985976\n",
      " 0.44265407 0.4359277  0.42972532 0.4275329 ]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "loader_te = DataLoader(test, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Get predictions\n",
    "predictions = trainer.predict(lit_model, loader_te)\n",
    "\n",
    "# predictions is a list of tensors (one per batch)\n",
    "# Concatenate to get all predictions\n",
    "all_predictions = torch.cat(predictions).cpu().numpy()\n",
    "\n",
    "print(f\"Predictions shape: {all_predictions.shape}\")\n",
    "print(f\"First 10 predictions: {all_predictions[:10]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Save & Load Model\n",
    "\n",
    "PyTorch Lightning offers several ways to save and load models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 1: Using ModelCheckpoint callback (already done during training)\n",
    "# The best model is automatically saved\n",
    "\n",
    "# Method 2: Manual save\n",
    "model_path = \"models/my-graph-classifier.ckpt\"\n",
    "trainer.save_checkpoint(model_path)\n",
    "\n",
    "# Method 3: Save just the model weights (not trainer state)\n",
    "torch.save(lit_model.state_dict(), \"models/my-model-weights.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading a Saved Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc3544d3636447619baebbc8703edb34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model predictions shape: (83,)\n"
     ]
    }
   ],
   "source": [
    "# Method 1: Load from Lightning checkpoint (Recommended)\n",
    "loaded_model = PyGLightningCrystalGraphClassifier.load_from_checkpoint(\n",
    "    \"models/my-graph-classifier.ckpt\"\n",
    ")\n",
    "\n",
    "# Create new trainer for loaded model\n",
    "new_trainer = pyl.Trainer(accelerator=\"auto\")\n",
    "\n",
    "# Make predictions\n",
    "loader_te = DataLoader(test, batch_size=32, shuffle=False)\n",
    "predictions = new_trainer.predict(loaded_model, loader_te)\n",
    "all_predictions = torch.cat(predictions).cpu().numpy()\n",
    "\n",
    "print(f\"Loaded model predictions shape: {all_predictions.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 2: Load just weights (requires you to create model first)\n",
    "loaded_model = PyGLightningCrystalGraphClassifier(\n",
    "    n_layers=3, channels=128, drop_out=0.5, n_out=1\n",
    ")\n",
    "loaded_model.load_state_dict(torch.load(\"models/my-model-weights.pth\"))\n",
    "loaded_model.eval()\n",
    "\n",
    "# Initialize lazy layers before using\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "loaded_model.to(device)\n",
    "sample_batch = next(iter(loader_te))\n",
    "sample_batch = sample_batch.to(device)\n",
    "with torch.no_grad():\n",
    "    _ = loaded_model(\n",
    "        sample_batch.x,\n",
    "        sample_batch.edge_index,\n",
    "        sample_batch.edge_attr,\n",
    "        sample_batch.batch,\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
