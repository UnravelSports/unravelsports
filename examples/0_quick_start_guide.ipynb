{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸŒ€ Quick Start Guide: It's all starting to unravel!\n",
    "\n",
    "In this example we'll run through all the basic features the `unravelsports` package offers for converting a `kloppy` dataset of soccer tracking data into graphs for training binary classification graph neural networks using the `spektral` library.\n",
    "\n",
    "This guide will go through the following steps:\n",
    "\n",
    "- [**1. Process Data**](#1-processing-data). We'll show how to load a `kloppy` dataset and convert each individual frame into a single graph. All necessary steps (like setting the correct coordinate system, and left-right normalization) are done under the hood of the converter.\n",
    "- [**1.1 Split Data**](#11-split-data).\n",
    "- [**2. Compile Model**](#2-compile-model). We compile the built-in binary classification model as presented in [A Graph Neural Network Deep-dive into Successful Counterattacks {A. Sahasrabudhe & J. Bekkers}](https://github.com/USSoccerFederation/ussf_ssac_23_soccer_gnn).\n",
    "- [**3. Fit Model**](#3-fit-model). Using the compiled model we fit it on the training set created in step [1.1 Splitting Data](#11-split-data).\n",
    "- [**4. Evaluate Model Performance**](#4-evaluate-model-performance). We calculated model performance using the `metrics` passed into the compiled model.\n",
    "- [**5. Predict**](#5-predict). Finally, we apply the trained model to unseen data.\n",
    "\n",
    "<br>\n",
    "<i>Before we get started it is important to note that the <b>unravelsports</b> library does not have built in functionality to create binary labels, these will need to be supplied by the reader. In this example we use the <b>dummy_labels()</b> functionality that comes with the package. This function creates a single binary label for each frame by randomly assigning it a 0 or 1 value.\n",
    "\n",
    "When supplying your own labels they need to be in the form of a dictionary (more information on this can be found in the [in-depth Walkthrough](1_kloppy_gnn_train.ipynb)) </i>\n",
    "\n",
    "\n",
    "\n",
    "-----\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing is to run `pip install unravelsports` if you haven't already!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install unravelsports --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Process Data\n",
    "\n",
    "1. Load [Kloppy](https://github.com/PySport/kloppy) dataset. \n",
    "    See [in-depth Tutorial](1_kloppy_gnn_train.ipynb) on how do processes multiple match files, and to see an overview of all possible settings.\n",
    "2. Convert to Graph format using `SoccerGraphConverter`\n",
    "3. Create dataset for easy processing with [Spektral](https://graphneural.network/) using `GraphDataset`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unravel.soccer import SoccerGraphConverter, KloppyPolarsDataset\n",
    "from unravel.utils import GraphDataset\n",
    "\n",
    "from kloppy import sportec\n",
    "\n",
    "# Load Kloppy dataset\n",
    "kloppy_dataset = sportec.load_open_tracking_data(only_alive=True, limit=500)\n",
    "kloppy_polars_dataset = KloppyPolarsDataset(\n",
    "    kloppy_dataset=kloppy_dataset,\n",
    ")\n",
    "kloppy_polars_dataset.add_dummy_labels()\n",
    "kloppy_polars_dataset.add_graph_ids(by=[\"frame_id\"])\n",
    "\n",
    "# Initialize the Graph Converter with dataset\n",
    "# Here we use the default settings\n",
    "converter = SoccerGraphConverter(dataset=kloppy_polars_dataset)\n",
    "\n",
    "# Compute the graphs and add them to the GraphDataset\n",
    "dataset = GraphDataset(graphs=converter.to_spektral_graphs())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 Split Data\n",
    "\n",
    "Split the dataset with the built in `split_test_train_validation` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spektral.data import DisjointLoader\n",
    "\n",
    "train, test, val = dataset.split_test_train_validation(\n",
    "    split_train=4, split_test=1, split_validation=1, random_seed=43\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Compile Model\n",
    "\n",
    "1. Initialize the `CrystalGraphClassifier`.\n",
    "2. Compile the model with a loss function, optimizer and your preferred metrics.\n",
    "\n",
    "Note: The model settings are chosen to reflect the model used in [A Graph Neural Network Deep-dive into Successful Counterattacks {A. Sahasrabudhe & J. Bekkers}](https://github.com/USSoccerFederation/ussf_ssac_23_soccer_gnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    }
   ],
   "source": [
    "from unravel.classifiers import CrystalGraphClassifier\n",
    "\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import AUC, BinaryAccuracy\n",
    "\n",
    "model = CrystalGraphClassifier()\n",
    "\n",
    "model.compile(\n",
    "    loss=BinaryCrossentropy(), optimizer=Adam(), metrics=[AUC(), BinaryAccuracy()]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Fit Model\n",
    "\n",
    "1. Create a [`DisjointLoader`](https://graphneural.network/loaders/#disjointloader) for training and validation sets.\n",
    "2. Fit the model. Note: set `use_multiprocessing=True` to speed up training significantly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jbekkers/PycharmProjects/unravelsports/.venv311/lib/python3.11/site-packages/keras/src/initializers/initializers.py:120: UserWarning: The initializer GlorotUniform is unseeded and being called multiple times, which will return identical values each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initializer instance more than once.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 1s 16ms/step - loss: 21.7806 - auc: 0.5278 - binary_accuracy: 0.5419 - val_loss: 5.1682 - val_auc: 0.5000 - val_binary_accuracy: 0.5000\n",
      "Epoch 2/10\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 9.2846 - auc: 0.3651 - binary_accuracy: 0.5000WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 3 batches). You may need to use the repeat() function when building your dataset.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 3 batches). You may need to use the repeat() function when building your dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 6ms/step - loss: 4.5155 - auc: 0.5366 - binary_accuracy: 0.5449\n",
      "Epoch 3/10\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 2.0773 - auc: 0.4515 - binary_accuracy: 0.4731\n",
      "Epoch 4/10\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1.1006 - auc: 0.5205 - binary_accuracy: 0.5150\n",
      "Epoch 5/10\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.9159 - auc: 0.4915 - binary_accuracy: 0.5180\n",
      "Epoch 6/10\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.8020 - auc: 0.4873 - binary_accuracy: 0.5060\n",
      "Epoch 7/10\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.8067 - auc: 0.4960 - binary_accuracy: 0.5299\n",
      "Epoch 8/10\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.7808 - auc: 0.5055 - binary_accuracy: 0.5299\n",
      "Epoch 9/10\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7661 - auc: 0.4937 - binary_accuracy: 0.5060\n",
      "Epoch 10/10\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.7406 - auc: 0.5098 - binary_accuracy: 0.5329\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x39fe49d10>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "batch_size = 32\n",
    "epochs = 10\n",
    "\n",
    "loader_tr = DisjointLoader(train, batch_size=batch_size)\n",
    "loader_va = DisjointLoader(val, epochs=1, shuffle=False, batch_size=batch_size)\n",
    "\n",
    "model.fit(\n",
    "    loader_tr.load(),\n",
    "    epochs=epochs,\n",
    "    steps_per_epoch=loader_tr.steps_per_epoch,\n",
    "    use_multiprocessing=True,\n",
    "    validation_data=loader_va.load(),\n",
    "    callbacks=[EarlyStopping(monitor=\"loss\", patience=5, restore_best_weights=True)],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Evaluate Model Performance\n",
    "\n",
    "1. Create another `DisjointLoader`, this time for the test set.\n",
    "2. Evaluate model performance on the test set. This evaluation function uses the `metrics` passed to `model.compile`\n",
    "\n",
    "Note: Our performance is really bad because we're using random labels, very few epochs and a small dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 6ms/step - loss: 0.7001 - auc: 0.5000 - binary_accuracy: 0.4819\n"
     ]
    }
   ],
   "source": [
    "loader_te = DisjointLoader(test, epochs=1, shuffle=False, batch_size=batch_size)\n",
    "results = model.evaluate(loader_te.load())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Predict\n",
    "\n",
    "1. Use unseen data to predict on. In this example we're using the test dataset.\n",
    "2. We have to re-create `loader_te` because `DisjointLoader` is a generator.\n",
    "3. Setting `batch_size` and `use_multiprocessing=True` on prediction helps speed up the prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 5ms/step\n"
     ]
    }
   ],
   "source": [
    "loader_te = DisjointLoader(test, batch_size=batch_size, epochs=1, shuffle=False)\n",
    "loaded_pred = model.predict(loader_te.load(), use_multiprocessing=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
